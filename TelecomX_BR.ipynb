{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4foVEKhrlqcH"
      },
      "source": [
        "#üìå Extrac√£o"
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Carregar os dados
url = "https://raw.githubusercontent.com/ingridcristh/challenge2-data-science/refs/heads/main/TelecomX_Data.json"
df = pd.read_json(url)

# Transformar colunas contendo dicion√°rios em DataFrames separados
account_df = df["account"].apply(pd.Series)
df = pd.concat([df, account_df], axis=1)

internet_df = df["internet"].apply(pd.Series)
df = pd.concat([df, internet_df], axis=1)

phone_df = df["phone"].apply(pd.Series)
df = pd.concat([df, phone_df], axis=1)

customer_df = df["customer"].apply(pd.Series)
df = pd.concat([df, customer_df], axis=1)

# Converter vari√°veis categ√≥ricas para num√©ricas (exemplo: 'Churn')
df["Churn"] = df["Churn"].map({"Yes": 1, "No": 0})

# Selecionar apenas colunas num√©ricas
df_numeric = df.select_dtypes(include=["number"])

# Calcular matriz de correla√ß√£o
corr_matrix = df_numeric.corr()

# Criar matriz de correla√ß√£o visual
plt.figure(figsize=(10, 6))
sns.heatmap(corr_matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Matriz de Correla√ß√£o das Vari√°veis Num√©ricas")
plt.show()

      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1--uPM88l7JH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lSZP8zmmGZu"
      },
      "source": [
        "#üîß Transforma√ß√£o"
import requests
import pandas as pd

# URL do arquivo JSON
url = "https://raw.githubusercontent.com/jlima2020/challenge2-data-science/main/TelecomX_Data.json"

# Fazendo a requisi√ß√£o
response = requests.get(url)

# Verificando se a requisi√ß√£o foi bem-sucedida
if response.status_code == 200:
    data = response.json()

    # Convertendo JSON para DataFrame
    df = pd.DataFrame(data)

    # Visualizando as primeiras linhas
    print(df.head())

else:
    print(f"Erro ao acessar os dados: {response.status_code}")


# Verificar as primeiras linhas do dataset
print(df.head())

# Exibir informa√ß√µes sobre as colunas e tipos de dados
print(df.info())

# Verificar os tipos de dados de cada coluna
print(df.dtypes)

import pandas as pd

# Exibindo informa√ß√µes gerais do DataFrame
print("== Informa√ß√µes Gerais ==")
print(df.info())

# Visualizando os tipos de dados
print("\n== Tipos de Dados ==")
print(df.dtypes)

# Checando valores ausentes em cada coluna
print("\n== Valores Ausentes ==")
print(df.isnull().sum())

# Verificando registros duplicados
# Before checking for duplicates, identify columns that might contain unhashable types like dictionaries.
# We can iterate through object type columns and check the type of their elements.
object_cols = df.select_dtypes(include=['object']).columns
cols_to_drop_for_dup_check = []
for col in object_cols:
    try:
        # Attempt to apply a hashable operation to see if it fails
        df[col].apply(hash)
    except TypeError:
        print(f"Coluna '{col}' parece conter tipos n√£o hashable (como dicion√°rios).")
        # If this column is not essential for duplicate checking, consider excluding it.
        # For simplicity, let's assume we can drop such columns for the duplicate check.
        cols_to_drop_for_dup_check.append(col)


# Check for duplicates, excluding columns identified as potentially containing unhashable types.
# If cols_to_drop_for_dup_check is empty, df_for_dup_check will be the original df.
df_for_dup_check = df.drop(columns=cols_to_drop_for_dup_check, errors='ignore')

# Now perform the duplicate check on the potentially modified DataFrame
dup_count = df_for_dup_check.duplicated().sum()
print(f"\n== Registros Duplicados: {dup_count} ==")


# Checando inconsist√™ncias em colunas categ√≥ricas (usando pandas.unique)
# We should only perform unique check on columns that are actually categorical strings,
# not potentially dictionary columns.
categorical_columns = df.select_dtypes(include=['object']).columns
for col in categorical_columns:
    # Skip columns we identified as having unhashable types if we are not processing them
    if col in cols_to_drop_for_dup_check:
         print(f"\nSkipping unique value check for column '{col}' due to unhashable types.")
         continue
    unique_values = df[col].unique()
    print(f"\nColuna '{col}' - Valores √önicos:")
    print(unique_values)

# Se houver colunas com datas, √© importante padroniz√°-las.
# Suponha que haja uma coluna 'data_registro' que precise ser convertida.
if 'data_registro' in df.columns:
    # Converter a coluna para o tipo datetime
    df['data_registro'] = pd.to_datetime(df['data_registro'], errors='coerce')

    # Normalizando a data (removendo a parte do tempo)
    df['data_registro_normalizada'] = df['data_registro'].dt.normalize()

    print("\n== Exemplo de Normaliza√ß√£o de Datas ==")
    print(df[['data_registro', 'data_registro_normalizada']].head())
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsm-WTLjmHvt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XnTC2NTmMRL"
      },
      "source": [
        "#üìä Carga e an√°lise"
import matplotlib.pyplot as plt
import seaborn as sns

# Verificar se a coluna 'Churn' existe no DataFrame
if 'Churn' in df_cleaned.columns:
    # Contar os valores de churn
    churn_counts = df_cleaned['Churn'].value_counts()

    # Criar o gr√°fico de barras
    plt.figure(figsize=(8, 6))
    sns.barplot(x=churn_counts.index, y=churn_counts.values, palette="pastel")
    plt.xlabel("Status do Cliente")
    plt.ylabel("N√∫mero de Clientes")
    plt.title("Distribui√ß√£o de Clientes evas√£o")
    plt.xticks(ticks=[0, 1], labels=["Permaneceu", "Saiu"])
    plt.show()
else:
    print("Erro: A coluna 'Churn' n√£o foi encontrada no DataFrame.")

      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jgUnLqTmPdd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-WzfSvTmaw9"
      },
      "source": [
        "#üìÑRelatorio Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMTac0YJmeK9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
